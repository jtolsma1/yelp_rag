{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d434799d",
   "metadata": {},
   "source": [
    "# Clean and Chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786eb0e4",
   "metadata": {},
   "source": [
    "**Setup & Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16c739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "current_dir = \"/Users/josephtolsma/Documents/dev/yelp_rag\"\n",
    "sys.path.insert(0,current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ee289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import DATA_DIR_SAMP,DATA_DIR_PROC,COL_TEXT, \\\n",
    "                       MIN_REVIEW_CHARS, CHUNK_CHARS,OVERLAP_CHARS, \\\n",
    "                       MIN_CHUNK_CHARS\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "pd.set_option(\"display.max_colwidth\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea60011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv(os.path.join(DATA_DIR_SAMP,\"reviews_df.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14135b8b",
   "metadata": {},
   "source": [
    "**Cleaning Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3495f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review_text(df):\n",
    "    \"for dataframe df, remove nonstandard characters and drop unusable (too short) values\"\n",
    "\n",
    "    before = len(df)\n",
    "    # basic cleaning    \n",
    "    df[COL_TEXT] = df[COL_TEXT].astype(\"string\").str.strip()\n",
    "    df = df.dropna(subset = [COL_TEXT])\n",
    "\n",
    "    # remove ultra-short reviews\n",
    "    df = df[df[COL_TEXT].str.len() >= MIN_REVIEW_CHARS]\n",
    "\n",
    "    # remove nonstandard characters\n",
    "    invalid_chars = {\n",
    "        \"\\u00a0\":\" \",\n",
    "        \"\\u002b\":\"\",\n",
    "        \"\\xa0\":\" \",\n",
    "        \"\\x0b\":\" \",\n",
    "        \"“\":'\"',\n",
    "        \"’\": \"'\",\n",
    "    }\n",
    "    \n",
    "    for char,rep_str in invalid_chars.items():\n",
    "        df[COL_TEXT] = df[COL_TEXT].str.replace(char,rep_str,regex = False)\n",
    "\n",
    "    df[COL_TEXT] = df[COL_TEXT].str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    \n",
    "    print(f\"{before - len(df)} reviews dropped in cleaning step.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa30071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_unicode(text):\n",
    "    \"convert all characters to standard unicode\"\n",
    "    return unicodedata.normalize(\"NFKC\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8f70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_reviews(df):\n",
    "    \"remove duplicated review texts from the dataset\"\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates(subset = [COL_TEXT])\n",
    "    print(f\"{before - len(df)} reviews dropped in deduplicating step.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182cd6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = clean_review_text(reviews_df)\n",
    "reviews_df[COL_TEXT] = reviews_df[COL_TEXT].apply(normalize_unicode)\n",
    "reviews_df = deduplicate_reviews(reviews_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701670fe",
   "metadata": {},
   "source": [
    "**Chunking Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd91da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_review = reviews_df[reviews_df[COL_TEXT].str.len() > 1100][COL_TEXT].sample(1,random_state=42).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e69eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_dict = {}\n",
    "# char_idx = 0\n",
    "# chunk_idx = 0\n",
    "# while char_idx < len(test_review):\n",
    "#     upcoming_chunk_length = len(test_review) - char_idx + OVERLAP_CHARS\n",
    "#     if len(test_review) <= CHUNK_CHARS:\n",
    "#         chunk_dict.update(\n",
    "#             {\"_0\":test_review}\n",
    "#             )\n",
    "#     elif char_idx == 0:\n",
    "#         chunk_dict.update(\n",
    "#             {\"_\"+str(chunk_idx):test_review[0:CHUNK_CHARS]}\n",
    "#             )\n",
    "#     elif upcoming_chunk_length > MIN_CHUNK_CHARS:\n",
    "#         chunk_dict.update(\n",
    "#             {\"_\"+str(chunk_idx):test_review[(char_idx - OVERLAP_CHARS):(char_idx+CHUNK_CHARS-OVERLAP_CHARS)]}\n",
    "#             )\n",
    "#     else:\n",
    "#         print(f\"Chunk dropped because it was smaller than minimum size of {MIN_CHUNK_CHARS} characters.\")\n",
    "#     chunk_idx +=1\n",
    "#     char_idx+=(CHUNK_CHARS - OVERLAP_CHARS)\n",
    "\n",
    "# df = pd.DataFrame(chunk_dict,index = [\"chunk\"]).T.reset_index(names = [\"chunk_id\"])\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae57b33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_reviews_into_chunks(text):\n",
    "    chunk_dict = {}\n",
    "    char_idx = 0\n",
    "    chunk_idx = 0\n",
    "    while char_idx < len(text):\n",
    "        upcoming_chunk_length = len(text) - char_idx + OVERLAP_CHARS\n",
    "        if len(text) <= CHUNK_CHARS:\n",
    "            chunk_dict.update(\n",
    "                {0:text}\n",
    "                )\n",
    "        elif char_idx == 0:\n",
    "            chunk_dict.update(\n",
    "                {chunk_idx:text[0:CHUNK_CHARS]}\n",
    "                )\n",
    "        elif upcoming_chunk_length > MIN_CHUNK_CHARS:\n",
    "            chunk_dict.update(\n",
    "                {chunk_idx:text[(char_idx - OVERLAP_CHARS):(char_idx+CHUNK_CHARS-OVERLAP_CHARS)]}\n",
    "                )\n",
    "        chunk_idx +=1\n",
    "        char_idx+=(CHUNK_CHARS - OVERLAP_CHARS)\n",
    "\n",
    "        return pd.DataFrame(chunk_dict,index = [\"chunk\"]).T.reset_index(names = [\"chunk_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e245d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chunk_df(reviews_df):\n",
    "    chunk_df = pd.DataFrame()\n",
    "    for row in reviews_df.itertuples():\n",
    "        new_row = divide_reviews_into_chunks(row.text)\n",
    "        new_row[\"business_id\"] = row.business_id\n",
    "        new_row[\"review_id\"] = row.review_id\n",
    "        new_row[\"restaurant_name\"] = row.name\n",
    "        new_row[\"chunk_id\"] = f\"{row.review_id}_{new_row[\"chunk_index\"].values[0]}\"\n",
    "        new_row[\"n_chars\"] = new_row[\"chunk\"].str.len()\n",
    "        new_row[\"stars\"] = row.stars_restaurant\n",
    "        new_row[\"date\"] = row.date\n",
    "        chunk_df = pd.concat([chunk_df,new_row],axis = 0)\n",
    "        chunk_df = chunk_df.reset_index(drop = True)\n",
    "    return chunk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d715900",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chunks = generate_chunk_df(reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "198a8a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chunks.to_parquet(os.path.join(DATA_DIR_PROC,\"review_chunks.parquet\"),engine = \"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478fb583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
